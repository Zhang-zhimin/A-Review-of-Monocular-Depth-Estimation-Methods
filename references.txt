[1] Cui Jiyun, Zhang Hao, Han Hu, et al. Improving 2D face recognition via discriminative face depth estimation; proceedings of the 2018 International Conference on Biometrics (ICB), F, 2018 [C].
[2] Albarqouni S., Konrad U., Wang L., et al. Single-view X-ray depth recovery: toward a novel concept for image-guided interventions [J]. Int J Comput Assist Radiol Surg, 2016, 11(6): 873-80.
[3] Chen Long, Tang Wen, John Nigel W, et al. Augmented reality for depth cues in monocular minimally invasive surgery [J]. arXiv preprint arXiv:01243, 2017.
[4] Sielhorst Tobias, Bichlmeier Christoph, Heining Sandro Michael, Navab Nassir. Depth perception-a major issue in medical AR: evaluation study by twenty surgeons; proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention, F, 2006 [C].
[5] Kao Jiun-Yu, Tian Dong, Mansour Hassan, et al. Moving object segmentation using depth and optical flow in car driving sequences; proceedings of the 2016 IEEE International Conference on Image Processing (ICIP), F, 2016 [C].
[6] Feng Lele, Yang Xubo, Xiao Shuangjiu. MagicToon: A 2D-to-3D creative cartoon modeling system with mobile AR; proceedings of the 2017 IEEE Virtual Reality (VR), F, 2017 [C].
[7] Zhou Q. Y., Koltun V. Color Map Optimization for 3D Reconstruction with Consumer Depth Cameras [J]. Acm Transactions on Graphics, 2014, 33(4): 1-10.
[8] Shotton Jamie, Fitzgibbon Andrew, Cook Mat, et al. Real-time human pose recognition in parts from single depth images; proceedings of the CVPR 2011, F, 2011 [C].
[9] Fang Y. J., Masaki I., Horn B. Depth-based target segmentation for intelligent vehicles: Fusion of radar and binocular stereo [J]. Ieee Transactions on Intelligent Transportation Systems, 2002, 3(3): 196-202.
[10] Zimmermann Christian, Welschehold Tim, Dornhege Christian, et al. 3d human pose estimation in rgbd images for robotic task learning; proceedings of the 2018 IEEE International Conference on Robotics and Automation (ICRA), F, 2018 [C]. IEEE.
[11] Biber Peter, Andreasson Henrik, Duckett Tom, Schilling Andreas. 3D modeling of indoor environments by a mobile robot with a laser scanner and panoramic camera; proceedings of the 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)(IEEE Cat No 04CH37566), F, 2004 [C]. IEEE.
[12] Scharstein Daniel, Szeliski Richard. High-accuracy stereo depth maps using structured light; proceedings of the 2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003 Proceedings, F, 2003 [C]. IEEE.
[13] Han J., Shao L., Xu D., Shotton J. Enhanced computer vision with Microsoft Kinect sensor: a review [J]. IEEE Trans Cybern, 2013, 43(5): 1318-34.
[14] Zhu J., Wang L., Yang R., et al. Reliability Fusion of Time-of-Flight Depth and Stereo Geometry for High Quality Depth Maps [J]. IEEE Trans Pattern Anal Mach Intell, 2011, 33(7): 1400-14.
[15] Foix S., Alenya G., Torras C. Lock-in Time-of-Flight (ToF) Cameras: A Survey [J]. Ieee Sensors Journal, 2011, 11(9): 1917-26.
[16] Bartczak Bogumil, Koch Reinhard. Dense depth maps from low resolution time-of-flight depth and high resolution color views; proceedings of the International Symposium on Visual Computing, F, 2009 [C].
[17] Xu Gangwei, Wang Xianqi, Ding Xiaohuan, Yang Xin. Iterative geometry encoding volume for stereo matching; proceedings of the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, F, 2023 [C].
[18] Zhao Haoliang, Zhou Huizhou, Zhang Yongjun, et al. High-frequency stereo matching network; proceedings of the Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, F, 2023 [C].
[19] Chen W. F., Fu Z., Yang D. W., Deng J. Single-Image Depth Perception in the Wild [J]. Advances in Neural Information Processing Systems 29 (Nips 2016), 2016, 29.
[20] Lee S., Im S., Lin S., Kweon I. S. Learning Monocular Depth in Dynamic Scenes via Instance-Aware Projection Consistency [J]. Thirty-Fifth Aaai Conference on Artificial Intelligence, Thirty-Third Conference on Innovative Applications of Artificial Intelligence and the Eleventh Symposium on Educational Advances in Artificial Intelligence, 2021, 35: 1863-72.
[21] Sturm Peter, Triggs Bill. A factorization based algorithm for multi-image projective structure and motion; proceedings of the European conference on computer vision, F, 1996 [C]. Springer.
[22] Horn Berthold KP. Shape from shading: A method for obtaining the shape of a smooth opaque object from one view [J]. Massachusetts Institute of Technology, 1970.
[23] Woodham Robert J. Photometric method for determining surface orientation from multiple images [J]. Optical engineering, 1980, 19(1): 191139.
[24] Witkin Andrew P %J Artificial intelligence. Recovering surface shape and orientation from texture [J]. 1981, 17(1-3): 17-45.
[25] Martin W. N., Aggarwal J. K. Volumetric descriptions of objects from multiple views [J]. IEEE Trans Pattern Anal Mach Intell, 1983, 5(2): 150-8.
[26] Rajagopalan AN, Chaudhuri Subhasis. Optimal selection of camera parameters for recovery of depth from defocused images; proceedings of the Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition, F, 1997 [C]. IEEE.
[27] Luo Wenjie, Schwing Alexander G, Urtasun Raquel. Efficient deep learning for stereo matching; proceedings of the Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, F, 2016 [C].
[28] Ming Y., Meng X. Y., Fan C. X., Yu H. Deep learning for monocular depth estimation: A review [J]. Neurocomputing, 2021, 438: 14-33.
[29] Saxena Ashutosh, Chung Sung H, Ng Andrew Y. Learning depth from single monocular images; proceedings of the NIPS, F, 2005 [C].
[30] Silberman Nathan, Hoiem Derek, Kohli Pushmeet, Fergus Rob. Indoor segmentation and support inference from rgbd images; proceedings of the European conference on computer vision, F, 2012 [C]. Springer.
[31] Cordts Marius, Omran Mohamed, Ramos Sebastian, et al. The cityscapes dataset for semantic urban scene understanding; proceedings of the Proceedings of the IEEE conference on computer vision and pattern recognition, F, 2016 [C].
[32] Geiger Andreas, Lenz Philip, Urtasun Raquel. Are we ready for autonomous driving? the kitti vision benchmark suite; proceedings of the 2012 IEEE Conference on Computer Vision and Pattern Recognition, F, 2012 [C]. IEEE.
[33] Mayer Nikolaus, Ilg Eddy, HÃ¤usser Philip, et al. A Large Dataset to Train Convolutional Networks for Disparity, Optical Flow, and Scene Flow Estimation; proceedings of the Computer Vision and Pattern Recognition, F, 2016 [C].
[34] Eigen D., Puhrsch C., Fergus R. Depth Map Prediction from a Single Image using a Multi-Scale Deep Network [J]. Advances in Neural Information Processing Systems 27 (Nips 2014), 2014, 27: 2366-74.
[35] Saxena Ashutosh, Sun Min, Ng Andrew Y. Learning 3-d scene structure from a single still image; proceedings of the 2007 IEEE 11th international conference on computer vision, F, 2007 [C]. IEEE.
[36] Zheng Qinfen, Chellappa Rama. Estimation of illuminant direction, albedo, and shape from shading [J]. 2002.
[37] Zhang Ruo, Tsai Ping Sing, Cryer James Edwin, Shah Mubarak. Shape from shading: A survey [J]. Ieee Transactions on Pattern Analysis and Machine Intelligence, 1999, 21(8): 690-706.
[38] Bichsel Martin, Pentland Alex P. A simple algorithm for shape from shading; proceedings of the Proceedings 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, F, 1992 [C]. IEEE Computer Society.
[39] Pentland A. P. Local shading analysis [J]. IEEE Trans Pattern Anal Mach Intell, 1984, 6(2): 170-87.
[40] Zheng Q., Chellappa R. Estimation of illuminant direction, albedo, and shape from shading; proceedings of the IEEE Computer Society Conference on Computer Vision & Pattern Recognition, F, 2002 [C].
[41] Liao Yi, Zhao Rong-chun Analysis and evaluation of several typical SFS algorithms [J]. Journal of Image Graphics, 2001, 6(10): 953-61.
[42] Lowe David G. Object recognition from local scale-invariant features; proceedings of the Proceedings of the seventh IEEE international conference on computer vision, F, 1999 [C]. Ieee.
[43] Lowe D. G. Distinctive image features from scale-invariant keypoints [J]. International Journal of Computer Vision, 2004, 60(2): 91-110.
[44] Bay H., Ess A., Tuytelaars T., Van Gool L. Speeded-Up Robust Features (SURF) [J]. Computer Vision and Image Understanding, 2008, 110(3): 346-59.
[45] Dalal Navneet, Triggs Bill. Histograms of oriented gradients for human detection; proceedings of the 2005 IEEE computer society conference on computer vision and pattern recognition (CVPR'05), F, 2005 [C]. Ieee.
[46] Rublee Ethan, Rabaud Vincent, Konolige Kurt, Bradski Gary. ORB: An efficient alternative to SIFT or SURF; proceedings of the 2011 International conference on computer vision, F, 2011 [C]. Ieee.
[47] Viswanathan Deepak Geetha. Features from accelerated segment test (fast); proceedings of the Proceedings of the 10th workshop on Image Analysis for Multimedia Interactive Services, London, UK, F, 2009 [C].
[48] Frahm Jan-Michael, Fite-Georgel Pierre, Gallup David, et al. Building rome on a cloudless day; proceedings of the European conference on computer vision, F, 2010 [C]. Springer.
[49] Agarwal S., Furukawa Y., Snavely N., et al. Building Rome in a Day [J]. Communications of the Acm, 2011, 54(10): 105-12.
[50] Lou Yin, Snavely Noah, Gehrke Johannes. Matchminer: Efficient spanning structure mining in large image collections; proceedings of the European Conference on Computer Vision, F, 2012 [C]. Springer.
[51] Havlena Michal, Schindler Konrad. Vocmatch: Efficient multiview correspondence for structure from motion; proceedings of the European Conference on Computer Vision, F, 2014 [C]. Springer.
[52] Schonberger Johannes L, Berg Alexander C, Frahm Jan-Michael. Paige: pairwise image geometry encoding for improved efficiency in structure-from-motion; proceedings of the Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, F, 2015 [C].
[53] Schonberger Johannes L, Frahm Jan-Michael. Structure-from-motion revisited; proceedings of the Proceedings of the IEEE conference on computer vision and pattern recognition, F, 2016 [C].
[54] Jared Heinly, Schonberger Johannes L, Dunn Enrique, Frahm Jan-Michael. Reconstructing the world in six days; proceedings of the CVPR, F, 2015 [C].
[55] Sweeney Chris, Fragoso Victor, HÃ¶llerer Tobias, Turk Matthew. Large scale sfm with the distributed camera model; proceedings of the 2016 Fourth International Conference on 3D Vision (3DV), F, 2016 [C]. IEEE.
[56] Gherardi Riccardo, Farenzena Michela, Fusiello Andrea. Improving the efficiency of hierarchical structure-and-motion; proceedings of the 2010 IEEE computer society conference on computer vision and pattern recognition, F, 2010 [C]. IEEE.
[57] Sweeney Chris, Sattler Torsten, Hollerer Tobias, et al. Optimizing the viewing graph for structure-from-motion; proceedings of the Proceedings of the IEEE international conference on computer vision, F, 2015 [C].
[58] Wilson Kyle, Snavely Noah. Robust global translations with 1dsfm; proceedings of the European Conference on Computer Vision, F, 2014 [C]. Springer.
[59] Gibson James J. The Perception of the Visual World [J]. The American Journal of Psychology, 1951, 64(3).
[60] Loh Angeline M, Hartley Richard I. Shape from Non-homogeneous, Non-stationary, Anisotropic, Perspective Texture; proceedings of the BMVC, F, 2005 [C]. Citeseer.
[61] Texture Shape From. Shape from texture [J]. 1988.
[62] Kanatani Ken Ichi, Chou Tsai Chia. Shape from texture: General principle [J]. Artificial Intelligence, 1989, 38(1): 1-48.
[63] Woodham Robert J. Photometric stereo: A reflectance map technique for determining surface orientation from image intensity; proceedings of the Image understanding systems and industrial applications I, F, 1979 [C]. International Society for Optics and Photonics.
[64] Ikeuchi Katsushi %J IEEE Transactions on Pattern Analysis, Intelligence Machine. Determining surface orientations of specular surfaces by using the photometric stereo method [J]. 1981, (6): 661-9.
[65] Lee Kyoung Mu, Kuo C-CJ. Shape reconstruction from photometric stereo; proceedings of the Proceedings 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, F, 1992 [C]. IEEE Computer Society.
[66] Chen Chia-Yen, Klette Reinhard, Chen Chi-Fa. Shape from photometric stereo and contours; proceedings of the International Conference on Computer Analysis of Images and Patterns, F, 2003 [C]. Springer.
[67] Witkin Andrew P. Shape from contour [J]. 1980.
[68] Barrow Harry, Tenenbaum J, Hanson A, Riseman E Recovering intrinsic scene characteristics [J]. Comput Vis Syst, 1978, 2(3-26): 2.
[69] Nagai Takaaki, Naruse Takumi, Ikehara Masaaki, Kurematsu Akira. Hmm-based surface reconstruction from single images; proceedings of the Proceedings International Conference on Image Processing, F, 2002 [C]. IEEE.
[70] Rossi Lorenzo, Chakareski Jacob, Frossard Pascal, Colonnese Stefania A poisson hidden markov model for multiview video traffic [J]. IEEE/ACM transactions on Networking, 2014, 23(2): 547-58.
[71] Scharstein Daniel, Pal Chris. Learning conditional random fields for stereo; proceedings of the 2007 IEEE Conference on Computer Vision and Pattern Recognition, F, 2007 [C]. IEEE.
[72] Liu Beyang, Gould Stephen, Koller Daphne. Single image depth estimation from predicted semantic labels; proceedings of the 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, F, 2010 [C]. IEEE.
[73] Wu Changchang, Frahm Jan-Michael, Pollefeys Marc. Repetition-based dense single-view reconstruction; proceedings of the CVPR 2011, F, 2011 [C]. IEEE.
[74] Saxena A., Chung S. H., Ng A. Y. 3-d depth reconstruction from a single still image [J]. International Journal of Computer Vision, 2008, 76(1): 53-69.
[75] Karsch Kevin, Liu Ce, Kang Sing Bing Depth transfer: Depth extraction from video using non-parametric sampling [J]. IEEE transactions on pattern analysis machine intelligence, 2014, 36(11): 2144-58.
[76] Oliva Aude, Torralba Antonio. Modeling the shape of the scene: A holistic representation of the spatial envelope [J]. International journal of computer vision, 2001, 42: 145-75.
[77] Liu Ce, Yuen Jenny, Torralba Antonio. Sift flow: Dense correspondence across scenes and its applications [J]. IEEE transactions on pattern analysis and machine intelligence, 2010, 33(5): 978-94.
[78] Karsch Kevin, Liu Ce, Kang Sing Bing. Depth extraction from video using non-parametric sampling; proceedings of the Computer VisionâECCV 2012: 12th European Conference on Computer Vision, Florence, Italy, October 7-13, 2012, Proceedings, Part V 12, F, 2012 [C]. Springer.
[79] Konrad Janusz, Wang Meng, Ishwar Prakash. 2d-to-3d image conversion by learning depth from examples; proceedings of the 2012 IEEE Computer society conference on computer vision and pattern recognition workshops, F, 2012 [C]. IEEE.
[80] Liu Miaomiao, Salzmann Mathieu, He Xuming. Discrete-continuous depth estimation from a single image; proceedings of the Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, F, 2014 [C].
[81] Roy Anirban, Todorovic Sinisa. Monocular depth estimation using neural regression forest; proceedings of the Proceedings of the IEEE conference on computer vision and pattern recognition, F, 2016 [C].
[82] Kundu Jogendra Nath, Uppala Phani Krishna, Pahuja Anuj, Babu R Venkatesh. Adadepth: Unsupervised content congruent adaptation for depth estimation; proceedings of the Proceedings of the IEEE conference on computer vision and pattern recognition, F, 2018 [C].
[83] Eigen D., Fergus R. Predicting Depth, Surface Normals and Semantic Labels with a Common Multi-Scale Convolutional Architecture; proceedings of the 2015 IEEE International Conference on Computer Vision (ICCV), F, 2014 [C].
[84] Laina Iro, Rupprecht Christian, Belagiannis Vasileios, et al. Deeper depth prediction with fully convolutional residual networks; proceedings of the 2016 Fourth international conference on 3D vision (3DV), F, 2016 [C]. IEEE.
[85] Long Jonathan, Shelhamer Evan, Darrell Trevor. Fully convolutional networks for semantic segmentation; proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, F, 2015 [C].
[86] Xian Ke, Zhang Jianming, Wang Oliver, et al. Structure-guided ranking loss for single image depth prediction; proceedings of the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, F, 2020 [C].
[87] Yin Wei, Liu Yifan, Shen Chunhua, Yan Youliang. Enforcing geometric constraints of virtual normal for depth prediction; proceedings of the Proceedings of the IEEE/CVF International Conference on Computer Vision, F, 2019 [C].
[88] Xie Zhenda, Geng Zigang, Hu Jingcheng, et al. Revealing the dark secrets of masked image modeling; proceedings of the Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, F, 2023 [C].
[89] Simonyan Karen, Zisserman Andrew Very deep convolutional networks for large-scale image recognition [J]. Computer Science, 2014.
[90] He Kaiming, Zhang Xiangyu, Ren Shaoqing, Sun Jian. Deep residual learning for image recognition; proceedings of the Proceedings of the IEEE conference on computer vision and pattern recognition, F, 2016 [C].
[91] Zhang Z., Xu C., Yang J., et al. Progressive Hard-Mining Network for Monocular Depth Estimation [J]. IEEE Trans Image Process, 2018, 27(8): 3691-702.
[92] Ignatov Andrey, Malivenko Grigory, Plowman David, et al. Fast and Accurate Single-Image Depth Estimation on Mobile Devices, Mobile AI 2021 Challenge: Report; proceedings of the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, F, 2021 [C].
[93] Eldesokey Abdelrahman, Felsberg Michael, Holmquist Karl, Persson Michael. Uncertainty-aware cnns for depth completion: Uncertainty from beginning to end; proceedings of the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, F, 2020 [C].
[94] Kim Y., Jung H., Min D., Sohn K. Deep Monocular Depth Estimation via Integration of Global and Local Predictions [J]. IEEE Trans Image Process, 2018, 27(8): 4131-44.
[95] Fu Huan, Gong Mingming, Wang Chaohui, et al. Deep ordinal regression network for monocular depth estimation; proceedings of the Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, F, 2018 [C].
[96] Gan Yukang, Xu Xiangyu, Sun Wenxiu, Lin Liang. Monocular depth estimation with affinity, vertical pooling, and label enhancement; proceedings of the Proceedings of the European Conference on Computer Vision (ECCV), F, 2018 [C].
[97] Chakrabarti A., Shao J. Y., Shakhnarovich G. Depth from a Single Image by Harmonizing Overcomplete Local Network Predictions [J]. Advances in Neural Information Processing Systems 29 (Nips 2016), 2016, 29.
[98] Aich Shubhra, Vianney Jean Marie Uwabeza, Islam Md Amirul, Liu Mannat Kaur Bingbing. Bidirectional attention network for monocular depth estimation; proceedings of the 2021 IEEE International Conference on Robotics and Automation (ICRA), F, 2021 [C]. IEEE.
[99] Li Zhenyu, Chen Zehui, Liu Xianming, Jiang Junjun. Depthformer: Exploiting long-range correlation and local information for accurate monocular depth estimation [J]. Machine Intelligence Research, 2023, 20(6): 837-54.
[100] Patil Vaishakh, Sakaridis Christos, Liniger Alexander, Van Gool Luc. P3depth: Monocular depth estimation with a piecewise planarity prior; proceedings of the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, F, 2022 [C].
[101] Liu Ce, Kumar Suryansh, Gu Shuhang, et al. Va-depthnet: A variational approach to single image depth prediction [J]. arXiv preprint arXiv:230206556, 2023.
[102] Ning Jia, Li Chen, Zhang Zheng, et al. All in tokens: Unifying output space of visual tasks via soft token; proceedings of the Proceedings of the IEEE/CVF International Conference on Computer Vision, F, 2023 [C].
[103] Mancini M., Costante G., Valigi P., et al. Toward Domain Independence for Learning-Based Monocular Depth Estimation [J]. Ieee Robotics and Automation Letters, 2017, 2(3): 1778-85.
[104] CS Kumar Arun, Bhandarkar Suchendra M, Prasad Mukta. Depthnet: A recurrent neural network architecture for monocular depth prediction; proceedings of the Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, F, 2018 [C].
[105] Xingjian SHI, Chen Zhourong, Wang Hao, et al. Convolutional LSTM network: A machine learning approach for precipitation nowcasting; proceedings of the Advances in neural information processing systems, F, 2015 [C].
[106] Maslov Dmitrii, Makarov Ilya. Online supervised attention-based recurrent depth estimation from monocular video [J]. PeerJ Computer Science, 2020, 6: e317.
[107] Griffin Brent A, Corso Jason J. Depth from Camera Motion and Object Detection; proceedings of the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, F, 2021 [C].
[108] Wei Zizhuang, Zhu Qingtian, Min Chen, et al. Bidirectional hybrid LSTM based recurrent neural network for multi-view stereo [J]. IEEE Transactions on Visualization and Computer Graphics, 2022.
[109] Zoran Daniel, Isola Phillip, Krishnan Dilip, Freeman William T. Learning ordinal relationships for mid-level vision; proceedings of the Proceedings of the IEEE International Conference on Computer Vision, F, 2015 [C].
[110] Lee Jae-Han, Kim Chang-Su. Monocular depth estimation using relative depth maps; proceedings of the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, F, 2019 [C].
[111] Liu Fayao, Shen Chunhua, Lin Guosheng. Deep convolutional neural fields for depth estimation from a single image; proceedings of the Proceedings of the IEEE conference on computer vision and pattern recognition, F, 2015 [C].
[112] Xu Dan, Wang Wei, Tang Hao, et al. Structured attention guided convolutional neural fields for monocular depth estimation; proceedings of the Proceedings of the IEEE conference on computer vision and pattern recognition, F, 2018 [C].
[113] Ricci Elisa, Ouyang Wanli, Wang Xiaogang, Sebe Nicu Monocular depth estimation using multi-scale continuous crfs as sequential deep networks [J]. IEEE transactions on pattern analysis machine intelligence, 2018, 41(6): 1426-40.
[114] Li Bo, Shen Chunhua, Dai Yuchao, et al. Depth and surface normal estimation from monocular images using regression on deep features and hierarchical crfs; proceedings of the Proceedings of the IEEE conference on computer vision and pattern recognition, F, 2015 [C].
[115] Cao Yuanzhouhan, Wu Zifeng, Shen Chunhua. Estimating depth from monocular images as classification using deep fully convolutional residual networks [J]. IEEE Transactions on Circuits Systems for Video Technology, 2017, 28(11): 3174-82.
[116] Yuan Weihao, Gu Xiaodong, Dai Zuozhuo, et al. Neural window fully-connected crfs for monocular depth estimation; proceedings of the Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, F, 2022 [C].
[117] Li Bo, Shen Chunhua, Dai Yuchao, et al. Depth and surface normal estimation from monocular images using regression on deep features and hierarchical CRFs; proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, F, 2015 [C].
[118] Wang Peng, Shen Xiaohui, Lin Zhe, et al. Towards unified depth and semantic prediction from a single image; proceedings of the Proceedings of the IEEE conference on computer vision and pattern recognition, F, 2015 [C].
[119] Mousavian Arsalan, Pirsiavash Hamed, KoÅ¡eckÃ¡ Jana. Joint semantic segmentation and depth estimation with deep convolutional networks; proceedings of the 2016 Fourth International Conference on 3D Vision (3DV), F, 2016 [C]. IEEE.
[120] Bhat Shariq Farooq, Alhashim Ibraheem, Wonka Peter. Adabins: Depth estimation using adaptive bins; proceedings of the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, F, 2021 [C].
[121] Li Zhenyu, Wang Xuyang, Liu Xianming, Jiang Junjun. Binsformer: Revisiting adaptive bins for monocular depth estimation [J]. IEEE Transactions on Image Processing, 2024.
[122] Piccinelli Luigi, Sakaridis Christos, Yu Fisher. idisc: Internal discretization for monocular depth estimation; proceedings of the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, F, 2023 [C].
[123] Li Ruibo, Xian Ke, Shen Chunhua, et al. Deep attention-based classification network for robust depth prediction; proceedings of the Computer VisionâACCV 2018: 14th Asian Conference on Computer Vision, Perth, Australia, December 2â6, 2018, Revised Selected Papers, Part IV 14, F, 2019 [C]. Springer.
[124] Kong Shu, Fowlkes Charless. Pixel-wise attentional gating for scene parsing; proceedings of the 2019 IEEE Winter Conference on Applications of Computer Vision (WACV), F, 2019 [C]. IEEE.
[125] Huynh Lam, Nguyen-Ha Phong, Matas Jiri, et al. Guiding monocular depth estimation using depth-attention volume; proceedings of the European Conference on Computer Vision, F, 2020 [C].
[126] Ranftl RenÃ©, Bochkovskiy Alexey, Koltun Vladlen. Vision transformers for dense prediction; proceedings of the Proceedings of the IEEE/CVF international conference on computer vision, F, 2021 [C].
[127] Ibrahem Hatem, Salem Ahmed, Kang Hyun-Soo. Rt-vit: Real-time monocular depth estimation using lightweight vision transformers [J]. Sensors, 2022, 22(10): 3849.
[128] Zhang Xin, Abdelfattah Rabab, Song Yuqi, et al. Depth Monocular Estimation with Attention-based Encoder-Decoder Network from Single Image; proceedings of the 2022 IEEE 24th Int Conf on High Performance Computing & Communications; 8th Int Conf on Data Science & Systems; 20th Int Conf on Smart City; 8th Int Conf on Dependability in Sensor, Cloud & Big Data Systems & Application (HPCC/DSS/SmartCity/DependSys), F, 2022 [C]. IEEE.
[129] Lee Minhyeok, Hwang Sangwon, Park Chaewon, Lee Sangyoun. Edgeconv with attention module for monocular depth estimation; proceedings of the Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, F, 2022 [C].
[130] Agarwal Ashutosh, Arora Chetan. Depthformer: Multiscale vision transformer for monocular depth estimation with global local information fusion; proceedings of the 2022 IEEE International Conference on Image Processing (ICIP), F, 2022 [C]. IEEE.
[131] Liu Ze, Lin Yutong, Cao Yue, et al. Swin transformer: Hierarchical vision transformer using shifted windows; proceedings of the Proceedings of the IEEE/CVF international conference on computer vision, F, 2021 [C].
[132] Chen Y. R., Zhao H. T., Hu Z. W., Peng J. C. Attention-based context aggregation network for monocular depth estimation [J]. International Journal of Machine Learning and Cybernetics, 2021, 12(6): 1583-96.
[133] Agarwal Ashutosh, Arora Chetan. Attention attention everywhere: Monocular depth prediction with skip attention; proceedings of the Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, F, 2023 [C].
[134] Wu Bingyuan, Wang Yongxiong. Rich global feature guided network for monocular depth estimation [J]. Image and Vision Computing, 2022, 125: 104520.
[135] Shu Chang, Chen Ziming, Chen Lei, et al. SideRT: A real-time pure transformer architecture for single image depth estimation [J]. arXiv preprint arXiv:220413892, 2022.
[136] Gupta Arijit, Prince A Amalin, Fredo AR Jac, Robert Femi. Transformer-based Models for Supervised Monocular Depth Estimation; proceedings of the 2022 International Conference on Intelligent Controller and Computing for Smart Power (ICICCSP), F, 2022 [C]. IEEE.
[137] Goodfellow I. J., Pouget-Abadie J., Mirza M., et al. Generative Adversarial Nets [J]. Advances in Neural Information Processing Systems 27 (Nips 2014), 2014, 27: 2672-80.
[138] Abdulwahab Saddam, Rashwan Hatem A, Garcia Miguel Angel, et al. Adversarial learning for depth and viewpoint estimation from a single image [J]. IEEE Transactions on Circuits and Systems for Video Technology, 2020, 30(9): 2947-58.
[139] Zhang Shaoyong, Li Na, Qiu Chenchen, et al. Depth map prediction from a single image with generative adversarial nets [J]. Multimedia Tools and Applications, 2020, 79: 14357-74.
[140] Jung Hyungjoo, Kim Youngjung, Min Dongbo, et al. Depth prediction from a single image with conditional adversarial networks; proceedings of the 2017 IEEE International Conference on Image Processing (ICIP), F, 2017 [C]. IEEE.
[141] Gwn Lore Kin, Reddy Kishore, Giering Michael, Bernal Edgar A. Generative adversarial networks for depth map estimation from RGB video; proceedings of the Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, F, 2018 [C].
[142] Islam Naeem Ul, Park Jaebyung. Depth estimation from a single RGB image using fine-tuned generative adversarial network [J]. IEEE Access, 2021, 9: 32781-94.
[143] Hao Shengang, Zhang Li, Qiu Kefan, Zhang Zheng. Conditional generative adversarial network for monocular image depth map prediction [J]. Electronics, 2023, 12(5): 1189.
[144] Bhattad Anand, McKee Daniel, Hoiem Derek, Forsyth David. Stylegan knows normal, depth, albedo, and more [J]. Advances in Neural Information Processing Systems, 2024, 36.
[145] Li Yidi, Xiao Jun, Wang Yiqun, Lu Zhengda. DepthGAN: GAN-based depth generation from semantic layouts [J]. Computational Visual Media, 2024, 10(3): 505-22.
[146] Xia Zhihao, Sullivan Patrick, Chakrabarti Ayan. Generating and exploiting probabilistic monocular depth estimates; proceedings of the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, F, 2020 [C].
[147] Zeng Ziyao, Wang Daniel, Yang Fengyu, et al. Wordepth: Variational language prior for monocular depth estimation; proceedings of the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, F, 2024 [C].
[148] Saxena Saurabh, Kar Abhishek, Norouzi Mohammad, Fleet David J. Monocular depth estimation using diffusion models [J]. arXiv preprint arXiv:230214816, 2023.
[149] Garg Ravi, Bg Vijay Kumar, Carneiro Gustavo, Reid Ian. Unsupervised cnn for single view depth estimation: Geometry to the rescue; proceedings of the European conference on computer vision, F, 2016 [C]. Springer.
[150] Godard ClÃ©ment, Mac Aodha Oisin, Brostow Gabriel J. Unsupervised monocular depth estimation with left-right consistency; proceedings of the Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, F, 2017 [C].
[151] Jaderberg M., Simonyan K., Zisserman A., Kavukcuoglu K. Spatial Transformer Networks [J]. Advances in Neural Information Processing Systems 28 (Nips 2015), 2015, 28.
[152] Poggi Matteo, Tosi Fabio, Mattoccia Stefano. Learning monocular depth estimation with unsupervised trinocular assumptions; proceedings of the 2018 International conference on 3d vision (3DV), F, 2018 [C]. IEEE.
[153] Goldman Matan, Hassner Tal, Avidan Shai. Learn stereo, infer mono: Siamese networks for self-supervised, monocular, depth estimation; proceedings of the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, F, 2019 [C].
[154] Wong Alex, Soatto Stefano. Bilateral cyclic constraint and adaptive regularization for unsupervised monocular depth prediction; proceedings of the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, F, 2019 [C].
[155] Tosi Fabio, Aleotti Filippo, Poggi Matteo, Mattoccia Stefano. Learning monocular depth estimation infusing traditional stereo knowledge; proceedings of the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, F, 2019 [C].
[156] Wang Ruoyu, Yu Zehao, Gao Shenghua. PlaneDepth: Self-supervised depth estimation via orthogonal planes; proceedings of the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, F, 2023 [C].
[157] Chen Xingyu, Zhang Ruonan, Jiang Ji, et al. Self-supervised monocular depth estimation: Solving the edge-fattening problem; proceedings of the Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, F, 2023 [C].
[158] Zhou Junsheng, Wang Yuwang, Qin Kaihuai, Zeng Wenjun. Moving indoor: Unsupervised video depth learning in challenging environments; proceedings of the Proceedings of the IEEE/CVF International Conference on Computer Vision, F, 2019 [C].
[159] Zhou Tinghui, Brown Matthew, Snavely Noah, Lowe David G. Unsupervised learning of depth and ego-motion from video; proceedings of the Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, F, 2017 [C].
[160] Godard ClÃ©ment, Mac Aodha Oisin, Firman Michael, Brostow Gabriel J. Digging into self-supervised monocular depth estimation; proceedings of the Proceedings of the IEEE/CVF International Conference on Computer Vision, F, 2019 [C].
[161] Yang Zhenheng, Wang Peng, Xu Wei, et al. Unsupervised learning of geometry with edge-aware depth-normal consistency [J]. arXiv preprint arXiv:03665, 2017.
[162] Mahjourian Reza, Wicke Martin, Angelova Anelia. Unsupervised learning of depth and ego-motion from monocular video using 3d geometric constraints; proceedings of the Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, F, 2018 [C].
[163] Vijayanarasimhan Sudheendra, Ricco Susanna, Schmid Cordelia, et al. Sfm-net: Learning of structure and motion from video [J]. arXiv preprint arXiv:07804, 2017.
[164] Bian J. W., Zhan H. Y., Wang N. Y., et al. Unsupervised Scale-Consistent Depth Learning from Video [J]. International Journal of Computer Vision, 2021, 129(9): 2548-64.
[165] Ummenhofer Benjamin, Zhou Huizhong, Uhrig Jonas, et al. Demon: Depth and motion network for learning monocular stereo; proceedings of the Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, F, 2017 [C].
[166] Tang Chengzhou, Tan Ping. Ba-net: Dense bundle adjustment network [J]. arXiv preprint arXiv:04807, 2018.
[167] Wang Chaoyang, Buenaposada JosÃ© Miguel, Zhu Rui, Lucey Simon. Learning depth from monocular videos using direct methods; proceedings of the Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, F, 2018 [C].
[168] Li Ruihao, Wang Sen, Long Zhiqiang, Gu Dongbing. Undeepvo: Monocular visual odometry through unsupervised deep learning; proceedings of the 2018 IEEE international conference on robotics and automation (ICRA), F, 2018 [C]. IEEE.
[169] Zhan Huangying, Garg Ravi, Weerasekera Chamara Saroj, et al. Unsupervised learning of monocular depth estimation and visual odometry with deep feature reconstruction; proceedings of the Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, F, 2018 [C].
[170] Loo Shing Yan, Amiri Ali Jahani, Mashohor Syamsiah, et al. CNN-SVO: Improving the mapping in semi-direct visual odometry using single-image depth prediction; proceedings of the 2019 International Conference on Robotics and Automation (ICRA), F, 2019 [C]. IEEE.
[171] Yang Nan, Stumberg Lukas von, Wang Rui, Cremers Daniel. D3vo: Deep depth, deep pose and deep uncertainty for monocular visual odometry; proceedings of the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, F, 2020 [C].
[172] Shao Shuwei, Pei Zhongcai, Chen Weihai, et al. Self-supervised learning for monocular depth estimation on minimally invasive surgery scenes; proceedings of the 2021 IEEE International Conference on Robotics and Automation (ICRA), F, 2021 [C]. IEEE.
[173] Yang Nan, Wang Rui, Stuckler Jorg, Cremers Daniel. Deep virtual stereo odometry: Leveraging deep depth prediction for monocular direct sparse odometry; proceedings of the Proceedings of the European Conference on Computer Vision (ECCV), F, 2018 [C].
[174] Fan Chao, Yin Zhenyu, Xu Fulong, et al. Joint softâhard attention for self-supervised monocular depth estimation [J]. Sensors, 2021, 21(21): 6956.
[175] Jiang Chenweinan, Liu Haichun, Li Lanzhen, Pan Changchun. Attention-based self-supervised learning monocular depth estimation with edge refinement; proceedings of the 2021 IEEE International Conference on Image Processing (ICIP), F, 2021 [C]. IEEE.
[176] Song Xibin, Li Wei, Zhou Dingfu, et al. MLDA-Net: Multi-level dual attention-based network for self-supervised monocular depth estimation [J]. IEEE Transactions on Image Processing, 2021, 30: 4691-705.
[177] Liu Pengpeng, King Irwin, Lyu Michael R, Xu Jia. Flow2stereo: Effective self-supervised learning of optical flow and stereo matching; proceedings of the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, F, 2020 [C].
[178] Liu Siping, Tu Xiaohan, Xu Cheng, Li Renfa. Deep neural networks with attention mechanism for monocular depth estimation on embedded devices [J]. Future Generation Computer Systems, 2022, 131: 137-50.
[179] Xiang Jie, Wang Yun, An Lifeng, et al. Visual attention-based self-supervised absolute depth estimation using geometric priors in autonomous driving [J]. IEEE Robotics and Automation Letters, 2022, 7(4): 11998-2005.
[180] Vaswani A. Attention is all you need [J]. Advances in Neural Information Processing Systems, 2017.
[181] Varma Arnav, Chawla Hemang, Zonooz Bahram, Arani Elahe. Transformers in self-supervised monocular depth estimation with unknown camera intrinsics [J]. arXiv preprint arXiv:220203131, 2022.
[182] Zhang Ning, Nex Francesco, Vosselman George, Kerle Norman. Lite-mono: A lightweight cnn and transformer architecture for self-supervised monocular depth estimation; proceedings of the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, F, 2023 [C].
[183] Han Daechan, Shin Jeongmin, Kim Namil, et al. Transdssl: Transformer based depth estimation via self-supervised learning [J]. IEEE Robotics and Automation Letters, 2022, 7(4): 10969-76.
[184] Masoumian Armin, Rashwan Hatem A, Abdulwahab Saddam, et al. Gcndepth: Self-supervised monocular depth estimation based on graph convolutional network [J]. Neurocomputing, 2023, 517: 81-92.
[185] Wu Dunquan, Chen Chenglizhao. Saliency Driven Monocular Depth Estimation Based on Multi-scale Graph Convolutional Network; proceedings of the Chinese Conference on Pattern Recognition and Computer Vision (PRCV), F, 2023 [C]. Springer.
[186] Poggi Matteo, Aleotti Filippo, Tosi Fabio, Mattoccia Stefano. On the uncertainty of self-supervised monocular depth estimation; proceedings of the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, F, 2020 [C].
[187] Guizilini Vitor, Ambrus Rares, Pillai Sudeep, et al. 3d packing for self-supervised monocular depth estimation; proceedings of the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, F, 2020 [C].
[188] Johnston Adrian, Carneiro Gustavo. Self-supervised monocular trained depth estimation using self-attention and discrete disparity volume; proceedings of the Proceedings of the ieee/cvf conference on computer vision and pattern recognition, F, 2020 [C].
[189] Liu Zhong, Li Ran, Shao Shuwei, et al. Self-supervised monocular depth estimation with self-reference distillation and disparity offset refinement [J]. IEEE Transactions on Circuits and Systems for Video Technology, 2023, 33(12): 7565-77.
[190] Zhao Chaoqiang, Poggi Matteo, Tosi Fabio, et al. GasMono: Geometry-aided self-supervised monocular depth estimation for indoor scenes; proceedings of the Proceedings of the IEEE/CVF International Conference on Computer Vision, F, 2023 [C].
[191] Wei Yi, Zhao Linqing, Zheng Wenzhao, et al. Surrounddepth: Entangling surrounding views for self-supervised multi-camera depth estimation; proceedings of the Conference on robot learning, F, 2023 [C]. PMLR.
[192] Li Shunkai, Xue Fei, Wang Xin, et al. Sequential adversarial learning for self-supervised deep visual odometry; proceedings of the Proceedings of the IEEE/CVF International Conference on Computer Vision, F, 2019 [C].
[193] Almalioglu Yasin, Saputra Muhamad Risqi U, de Gusmao Pedro PB, et al. Ganvo: Unsupervised deep monocular visual odometry and depth estimation with generative adversarial networks; proceedings of the 2019 International conference on robotics and automation (ICRA), F, 2019 [C]. IEEE.
[194] Watson Jamie, Mac Aodha Oisin, Prisacariu Victor, et al. The temporal opportunist: Self-supervised multi-frame monocular depth; proceedings of the Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, F, 2021 [C].
[195] Wimbauer Felix, Yang Nan, Stumberg Lukas Von, et al. MonoRec: Semi-Supervised Dense Reconstruction in Dynamic Environments from a Single Moving Camera; proceedings of the Computer Vision and Pattern Recognition, F, 2021 [C].
[196] He Mu, Hui Le, Bian Yikai, et al. Ra-depth: Resolution adaptive self-supervised monocular depth estimation; proceedings of the European Conference on Computer Vision, F, 2022 [C]. Springer.
[197] Bae Jinwoo, Moon Sungho, Im Sunghoon. Monoformer: Towards generalization of self-supervised monocular depth estimation with transformers [J]. arXiv preprint arXiv:220511083, 2022, 1(2): 4.
[198] Zhao Chaoqiang, Zhang Youmin, Poggi Matteo, et al. Monovit: Self-supervised monocular depth estimation with a vision transformer; proceedings of the 2022 international conference on 3D vision (3DV), F, 2022 [C]. IEEE.
[199] Saunders Kieran, Vogiatzis George, Manso Luis J. Self-supervised Monocular Depth Estimation: Let's Talk About The Weather; proceedings of the Proceedings of the IEEE/CVF International Conference on Computer Vision, F, 2023 [C].
[200] Wang Youhong, Liang Yunji, Xu Hao, et al. Sqldepth: Generalizable self-supervised fine-structured monocular depth estimation; proceedings of the Proceedings of the AAAI Conference on Artificial Intelligence, F, 2024 [C].
[201] Petrovai Andra, Nedevschi Sergiu. MonoDVPS: A Self-Supervised Monocular Depth Estimation Approach to Depth-aware Video Panoptic Segmentation [J]. 2022.
[202] Caron Mathilde, Houlsby Neil, Schmid Cordelia. Location-Aware Self-Supervised Transformers for Semantic Segmentation; proceedings of the 2024 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), F].
[203] Yin Zhichao, Shi Jianping. Geonet: Unsupervised learning of dense depth, optical flow and camera pose; proceedings of the Proceedings of the IEEE conference on computer vision and pattern recognition, F, 2018 [C].
[204] Chen Yuhua, Schmid Cordelia, Sminchisescu Cristian. Self-supervised learning with geometric constraints in monocular video: Connecting flow, depth, and camera; proceedings of the Proceedings of the IEEE/CVF International Conference on Computer Vision, F, 2019 [C].
[205] Casser Vincent, Pirk Soeren, Mahjourian Reza, Angelova Anelia. Unsupervised monocular depth and ego-motion learning with structure and semantics; proceedings of the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, F, 2019 [C].
[206] Wang Lijun, Zhang Jianming, Wang Oliver, et al. Sdc-depth: Semantic divide-and-conquer network for monocular depth estimation; proceedings of the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, F, 2020 [C].
[207] Wang Qin, Dai Dengxin, Hoyer Lukas, et al. Domain adaptive semantic segmentation with self-supervised depth estimation; proceedings of the Proceedings of the IEEE/CVF International Conference on Computer Vision, F, 2021 [C].
[208] Ramirez Pierluigi Zama, Poggi Matteo, Tosi Fabio, et al. Geometry meets semantics for semi-supervised monocular depth estimation; proceedings of the Asian Conference on Computer Vision, F, 2018 [C]. Springer.
[209] Zhang Zhenyu, Cui Zhen, Xu Chunyan, et al. Joint task-recursive learning for semantic segmentation and depth estimation; proceedings of the Proceedings of the European Conference on Computer Vision (ECCV), F, 2018 [C].
[210] Chen Po-Yi, Liu Alexander H, Liu Yen-Cheng, Wang Yu-Chiang Frank. Towards scene understanding: Unsupervised monocular depth estimation with semantic-aware representation; proceedings of the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, F, 2019 [C].
[211] Klingner Marvin, TermÃ¶hlen Jan-Aike, Mikolajczyk Jonas, Fingscheidt Tim. Self-supervised monocular depth estimation: Solving the dynamic object problem by semantic guidance; proceedings of the European Conference on Computer Vision, F, 2020 [C]. Springer.
[212] Hoyer Lukas, Dai Dengxin, Wang Qin, et al. Improving semi-supervised and domain-adaptive semantic segmentation with self-supervised depth estimation [J]. International Journal of Computer Vision, 2023, 131(8): 2070-96.
[213] Li Rui, Xue Danna, Su Shaolin, et al. Learning depth via leveraging semantics: Self-supervised monocular depth estimation with both implicit and explicit semantic guidance [J]. Pattern Recognition, 2023, 137: 109297.
[214] Zhang Dongdong, Wang Chunping, Wang Huiying, Fu Qiang. Graph semantic information for self-supervised monocular depth estimation [J]. Pattern Recognition, 2024, 156: 110770.
[215] Wang Qi, Piao Yan. Depth estimation of supervised monocular images based on semantic segmentation [J]. Journal of Visual Communication and Image Representation, 2023, 90: 103753.
[216] Lopez-Rodriguez Adrian, Mikolajczyk Krystian. Desc: Domain adaptation for depth estimation via semantic consistency [J]. International Journal of Computer Vision, 2023, 131(3): 752-71.
[217] Huang Yuanhui, Zheng Wenzhao, Zhang Borui, et al. Selfocc: Self-supervised vision-based 3d occupancy prediction; proceedings of the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, F, 2024 [C].
[218] Ranjan Anurag, Jampani Varun, Balles Lukas, et al. Competitive collaboration: Joint unsupervised learning of depth, camera motion, optical flow and motion segmentation; proceedings of the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, F, 2019 [C].
[219] Zou Yuliang, Luo Zelun, Huang Jia-Bin. Df-net: Unsupervised joint learning of depth and flow using cross-task consistency; proceedings of the Proceedings of the European conference on computer vision (ECCV), F, 2018 [C].
[220] Guizilini Vitor, Lee Kuan-Hui, AmbruÅ RareÅ, Gaidon Adrien. Learning optical flow, depth, and scene flow without real-world labels [J]. IEEE Robotics and Automation Letters, 2022, 7(2): 3491-8.
[221] Lu Zhengyang, Chen Ying. Joint self-supervised depth and optical flow estimation towards dynamic objects [J]. Neural Processing Letters, 2023, 55(8): 10235-49.
[222] Sun Yiyang, Xu Zhiyuan, Wang Xiaonian, Yao Jing. FlowDepth: Decoupling Optical Flow for Self-Supervised Monocular Depth Estimation [J]. arXiv preprint arXiv:240319294, 2024.
[223] dos Santos Rosa NÃ­colas, Guizilini Vitor, Grassi Valdir. Sparse-to-continuous: Enhancing monocular depth estimation using occupancy maps; proceedings of the 2019 19th International Conference on Advanced Robotics (ICAR), F, 2019 [C]. IEEE.
[224] Qiu Jiaxiong, Cui Zhaopeng, Zhang Yinda, et al. Deeplidar: Deep surface normal guided depth prediction for outdoor scene from sparse lidar data and single color image; proceedings of the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, F, 2019 [C].
[225] Kuznietsov Yevhen, Stuckler Jorg, Leibe Bastian. Semi-supervised deep learning for monocular depth map prediction; proceedings of the Proceedings of the IEEE conference on computer vision and pattern recognition, F, 2017 [C].
[226] Chen Zhao, Badrinarayanan Vijay, Drozdov Gilad, Rabinovich Andrew. Estimating depth from rgb and sparse sensing; proceedings of the Proceedings of the European Conference on Computer Vision (ECCV), F, 2018 [C].
[227] Luo Yue, Ren Jimmy, Lin Mude, et al. Single view stereo matching; proceedings of the Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, F, 2018 [C].
[228] Guizilini Vitor, Li Jie, Ambrus Rares, et al. Robust semi-supervised monocular depth estimation with reprojected distances; proceedings of the Conference on robot learning, F, 2020 [C]. PMLR.
[229] Li Peixuan, Zhao Huaici. Monocular 3d detection with geometric constraint embedding and semi-supervised training [J]. IEEE Robotics and Automation Letters, 2021, 6(3): 5565-72.
[230] Duan Yiqun, Guo Xianda, Zhu Zheng. Diffusiondepth: Diffusion denoising approach for monocular depth estimation [J]. arXiv preprint arXiv:230305021, 2023.
[231] He L., Chen C. B., Zhang T., et al. Wearable Depth Camera: Monocular Depth Estimation via Sparse Optimization Under Weak Supervision [J]. Ieee Access, 2018, 6: 41337-45.
[232] Lin Juan-Ting, Dai Dengxin, Van Gool Luc. Depth estimation from monocular images and sparse radar data; proceedings of the 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), F, 2020 [C]. IEEE.
[233] Lo Chen-Chou, Vandewalle Patrick. Depth estimation from monocular images and sparse radar using deep ordinal regression network; proceedings of the 2021 IEEE International Conference on Image Processing (ICIP), F, 2021 [C]. IEEE.
[234] Zheng Ke, Li Shuguang, Qin Kongjian, et al. Depth estimation via sparse radar prior and driving scene semantics; proceedings of the Proceedings of the Asian Conference on Computer Vision, F, 2022 [C].
[235] Singh Akash Deep, Ba Yunhao, Sarker Ankur, et al. Depth estimation from camera image and mmwave radar point cloud; proceedings of the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, F, 2023 [C].
[236] Bartoccioni Florent, Zablocki Ãloi, PÃ©rez Patrick, et al. LiDARTouch: Monocular metric depth estimation with a few-beam LiDAR [J]. Computer Vision and Image Understanding, 2023, 227: 103601.
[237] Zheng Chuanxia, Cham Tat-Jen, Cai Jianfei. T2net: Synthetic-to-realistic translation for solving single-image depth estimation tasks; proceedings of the Proceedings of the European Conference on Computer Vision (ECCV), F, 2018 [C].
[238] Zhao Yunhan, Kong Shu, Shin Daeyun, Fowlkes Charless. Domain decluttering: Simplifying images to mitigate synthetic-real domain shift and improve depth estimation; proceedings of the Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, F, 2020 [C].
[239] Hoffman Judy, Tzeng Eric, Park Taesung, et al. Cycada: Cycle-consistent adversarial domain adaptation; proceedings of the International conference on machine learning, F, 2018 [C]. PMLR.
[240] Qi Xiaojuan, Liao Renjie, Liu Zhengzhe, et al. Geonet: Geometric neural network for joint depth and surface normal estimation; proceedings of the Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, F, 2018 [C].
[241] Fei X. H., Wong A., Soatto S. Geo-Supervised Visual Depth Prediction [J]. Ieee Robotics and Automation Letters, 2019, 4(2): 1661-8.
[242] Li Hanhan, Gordon Ariel, Zhao Hang, et al. Unsupervised Monocular Depth Learning in Dynamic Scenes [J]. arXiv:201016404, 2020: 2010.
[243] Li Yuanzhen, Luo Fei, Xiao Chunxia. Self-supervised coarse-to-fine monocular depth estimation using a lightweight attention module [J]. Computational Visual Media, 2022, 8(4): 631-47.
[244] Hwang Seung-Jun, Park Sung-Jun, Baek Joong-Hwan, Kim Byungkyu. Self-supervised monocular depth estimation using hybrid transformer encoder [J]. IEEE Sensors Journal, 2022, 22(19): 18762-70.
[245] Wang Jiyuan, Lin Chunyu, Nie Lang, et al. Weatherdepth: Curriculum contrastive learning for self-supervised depth estimation under adverse weather conditions; proceedings of the 2024 IEEE International Conference on Robotics and Automation (ICRA), F, 2024 [C]. IEEE.